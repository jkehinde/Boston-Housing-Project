{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LeamvpPVXuS_"
   },
   "source": [
    "# Random Forest Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O2wvZ7SKXzVC"
   },
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PVmESEFZX4Ig"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zgbK_F8-X7em"
   },
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "adBE4tjQX_Bh"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Housing.csv')\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ptNjcy7bOBlD"
   },
   "source": [
    "## Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C7NdofoCOFQF"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v4S2fyIBYDcu"
   },
   "source": [
    "## Training the Random Forest Regression model on the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o8dOCoJ1YKMc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=10, n_jobs=None, oob_score=False,\n",
       "                      random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators = 10, random_state = 0)\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DM_jh0frOPKE"
   },
   "source": [
    "## Predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JGa9ZfM4OTNw",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[425040. 417900.]\n",
      " [642600. 632100.]\n",
      " [328860. 281400.]\n",
      " [279930. 577500.]\n",
      " [507990. 474600.]\n",
      " [263550. 359100.]\n",
      " [322140. 247800.]\n",
      " [439320. 474600.]\n",
      " [450030. 449400.]\n",
      " [344400. 411600.]\n",
      " [223650. 214200.]\n",
      " [292740. 214200.]\n",
      " [454440. 428400.]\n",
      " [237510. 375900.]\n",
      " [531300. 577500.]\n",
      " [334950. 327600.]\n",
      " [426930. 420000.]\n",
      " [529200. 489300.]\n",
      " [431130. 470400.]\n",
      " [616560. 640500.]\n",
      " [535920. 651000.]\n",
      " [753060. 690900.]\n",
      " [244440. 147000.]\n",
      " [423360. 441000.]\n",
      " [436170. 367500.]\n",
      " [896490. 966000.]\n",
      " [732060. 756000.]\n",
      " [905730. 888300.]\n",
      " [433860. 455700.]\n",
      " [452550. 445200.]\n",
      " [432810. 323400.]\n",
      " [395640. 455700.]\n",
      " [485520. 430500.]\n",
      " [687960. 867300.]\n",
      " [430290. 445200.]\n",
      " [894180. 875700.]\n",
      " [577710. 415800.]\n",
      " [222390. 268800.]\n",
      " [528360. 590100.]\n",
      " [556080. 497700.]\n",
      " [234570. 231000.]\n",
      " [360150. 315000.]\n",
      " [439950. 388500.]\n",
      " [497700. 449400.]\n",
      " [402780. 413700.]\n",
      " [339780. 352800.]\n",
      " [507990. 453600.]\n",
      " [300300. 306600.]\n",
      " [835380. 898800.]\n",
      " [425670. 514500.]\n",
      " [706440. 743400.]\n",
      " [395850. 474600.]\n",
      " [569100. 600600.]\n",
      " [325290. 304500.]\n",
      " [697410. 661500.]\n",
      " [576660. 489300.]\n",
      " [326340. 422100.]\n",
      " [263130. 184800.]\n",
      " [650580. 525000.]\n",
      " [413910. 249900.]\n",
      " [361620. 407400.]\n",
      " [266070. 361200.]\n",
      " [414120. 428400.]\n",
      " [419580. 392700.]\n",
      " [422100. 428400.]\n",
      " [410970. 472500.]\n",
      " [221550. 258300.]\n",
      " [539700. 550200.]\n",
      " [530880. 346500.]\n",
      " [274260. 199500.]\n",
      " [233100. 302400.]\n",
      " [514500. 611100.]\n",
      " [342930. 396900.]\n",
      " [520170. 585900.]\n",
      " [244860. 279300.]\n",
      " [421260. 483000.]\n",
      " [532140. 462000.]\n",
      " [307020. 218400.]\n",
      " [555450. 518700.]\n",
      " [356160. 420000.]\n",
      " [426300. 392700.]\n",
      " [920220. 980700.]\n",
      " [434700. 455700.]\n",
      " [607110. 514500.]\n",
      " [431760. 480900.]\n",
      " [630840. 520800.]\n",
      " [531300. 485100.]\n",
      " [488460. 525000.]\n",
      " [444150. 390600.]\n",
      " [373800. 569100.]\n",
      " [420840. 359100.]\n",
      " [319410. 346500.]\n",
      " [350700. 283500.]\n",
      " [284970. 344400.]\n",
      " [502950. 459900.]\n",
      " [497910. 464100.]\n",
      " [532560. 432600.]\n",
      " [589050. 617400.]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = regressor.predict(X_test)\n",
    "np.set_printoptions(precision=2)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cd8VZM5POWXN"
   },
   "source": [
    "## Evaluating the Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a7y1rXlfOZJo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7958582987098185"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Modelâ€™s Performance\n",
    "\n",
    "Graphing the models performance with varying criteria can help in the analysis process. We can identity valuable insights such as visualizing behavior that would not be apparent with the R2 scores alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'bootstrap': True,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'criterion': 'mse',\n",
      " 'max_depth': None,\n",
      " 'max_features': 'auto',\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_impurity_split': None,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 10,\n",
      " 'n_jobs': None,\n",
      " 'oob_score': False,\n",
      " 'random_state': 0,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# Here we are able to see all of our paramater for our randomforest regressor and the values they are set to\n",
    "\n",
    "from pprint import pprint #pprint allow the output to be printed in a structured format \n",
    "# Look at parameters used by our current forest\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(regressor.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to improve our model we will tune the folowing parameters:\n",
    "- n_estimators = number of trees in the foreset\n",
    "- max_features = max number of features considered for splitting a node\n",
    "- max_depth = max number of levels in each decision tree\n",
    "- min_samples_split = min number of data points placed in a node before the node is split\n",
    "- min_samples_leaf = min number of data points allowed in a leaf node\n",
    "- bootstrap = method for sampling data points (with or without replacement)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Hyperparameter Grid\n",
    "\n",
    "On each iteration, the algorithm will choose a difference combination of the features.The benefit of random search is that we are not using every combination, but selecting at random to sample a wide range of values\n",
    "\n",
    "To use RandomizedSearchCV, it is important to create a parameter grid to sample from during fitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False],\n",
      " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Search Training \n",
    "\n",
    "Now we are going to fit the random search module "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   36.8s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  8.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=RandomForestRegressor(bootstrap=True,\n",
       "                                                   ccp_alpha=0.0,\n",
       "                                                   criterion='mse',\n",
       "                                                   max_depth=None,\n",
       "                                                   max_features='auto',\n",
       "                                                   max_leaf_nodes=None,\n",
       "                                                   max_samples=None,\n",
       "                                                   min_impurity_decrease=0.0,\n",
       "                                                   min_impurity_split=None,\n",
       "                                                   min_samples_leaf=1,\n",
       "                                                   min_samples_split=2,\n",
       "                                                   min_weight_fraction_leaf=0.0,\n",
       "                                                   n_estimators=100,\n",
       "                                                   n_jobs=None, oob_score=Fals...\n",
       "                   iid='deprecated', n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=0, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune \n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=0, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2 most important arguments in RandomizedSearchCV are:\n",
    "- n_iter, which tells us the number of different combinations to try\n",
    "- cv which is the number of folds to use for cross validation (we use 100 and 3 respectively)\n",
    "\n",
    "More iterations will cover a wider space for our search and the more cv folds will prevent  the chances of the our model overfitting. The downside to increasing cv is that it increases the run time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1800,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': None,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will allow us to view the best parameters from fitting the random search. This will allow us to narrow the range for\n",
    "# each hyperparameter\n",
    "\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Random Search\n",
    "\n",
    "It is now important to determine if the random search yielded a better model. we compare the original regression model, \n",
    "with the best random search model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Average Error: 59271.4286 degrees.\n",
      "Accuracy = 85.21%.\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, X_test, y_test):\n",
    "    predictions = model.predict(X_test)\n",
    "    errors = abs(predictions - y_test)\n",
    "    mape = 100 * np.mean(errors / y_test)\n",
    "    accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "# notice this exactly the same as our regressor model from earlier on\n",
    "base_model = RandomForestRegressor(n_estimators = 10, random_state = 0)\n",
    "base_model.fit(X_train, y_train)\n",
    "base_accuracy = evaluate(base_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Average Error: 55649.1429 degrees.\n",
      "Accuracy = 85.58%.\n"
     ]
    }
   ],
   "source": [
    "best_random = rf_random.best_estimator_\n",
    "random_accuracy = evaluate(best_random, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improvement of 0.44%.\n"
     ]
    }
   ],
   "source": [
    "print('Improvement of {:0.2f}%.'.format( 100 * (random_accuracy - base_accuracy) / base_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the improvement in accuracy improved by 0.44%. We can improve this result even further using grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search with Cross Validation\n",
    "\n",
    "Random search gives us the opportunity to narrow the range of each hyperparameter. We can now concentrate our search, using the GridSearchCV. This method is much better than sampling randomly from a distribution.\n",
    "\n",
    "We will make another grid based on the best values provided by random search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "\n",
    "\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   20.1s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done 864 out of 864 | elapsed:  8.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 90,\n",
       " 'max_features': 2,\n",
       " 'min_samples_leaf': 4,\n",
       " 'min_samples_split': 8,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the grid search to the dataset\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Average Error: 53389.2454 degrees.\n",
      "Accuracy = 86.32%.\n"
     ]
    }
   ],
   "source": [
    "# This will give us Model performace of the GridSearchCV\n",
    "best_grid = grid_search.best_estimator_\n",
    "grid_accuracy = evaluate(best_grid, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improvement of 1.30%.\n"
     ]
    }
   ],
   "source": [
    "print('Improvement of {:0.2f}%.'.format( 100 * (grid_accuracy - base_accuracy) / base_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce a matrix for client data\n",
    "client_data = [[5, 17, 15], # Client 1\n",
    "               [4, 32, 22], # Client 2\n",
    "               [8, 3, 12]]  # Client 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted selling price for Client 1's home: $365,135.80\n",
      "Predicted selling price for Client 2's home: $228,913.45\n",
      "Predicted selling price for Client 3's home: $914,684.11\n"
     ]
    }
   ],
   "source": [
    "# Show predicitons on the original best_grid model\n",
    "for i, price in enumerate(best_grid.predict(client_data)):\n",
    "    print(\"Predicted selling price for Client {}'s home: ${:,.2f}\".format(i+1, price))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given these values we can conclude:\n",
    "    \n",
    "- Client 3 selling price is the near million dollars. This price seems very correct because of its features (8 rooms, very low poverty level and low student-teacher ratio). We can assume it is a wealthy neighborhood \n",
    "\n",
    "- Client 2 has the lowest price and this is because it has the least amount of rooms(RM), but the highest LSTAT, PTRATIO  \n",
    "\n",
    "- For client 1, we can see that its features are intermediate between the latter 2, and therefore, its price is quite near the mean and median.\n",
    "\n",
    "\n",
    "We can conclude that our hypothesis in the explanatory data analysis was correct"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "random_forest_regression.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
